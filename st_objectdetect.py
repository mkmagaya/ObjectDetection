# -*- coding: utf-8 -*-
"""kbsAssignmentTwo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15WxHjzIa26YKS9DTaPSmdLdZ2XOsQ_gc

**#OBJECT DETECTION USING OPEN-CV AND VGG16 MODEL**

MAGAYA MAKOMBORERO R181571B

MABHUKA B. OSWELL  R181573F

#this project was deployed using [Streamlit Share](https://share.streamlit.io/mkmagaya/objectdetection/main/app.py)
#the project was deployed via a [GitHub repository](https://github.com/mkmagaya/objectdetection)

#challenges faced
######we did not manage to successifully deploy our application on streamlit due to limited github upload capacity

#import necessary libraries
"""
import streamlit as st
import numpy as np
import os
import cv2
import json
from glob import glob
from PIL import Image
import glob
import cv2
import requests
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions


# from tensorflow.keras.models import load_model
# model = load_model('vgg16Model.h5')

# """#creating object for VGG16 pre-trained **model**"""

model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)

# """#plot model"""

# plot_model(model, to_file='vgg_model.png')

# """#model summary"""

# model.summary()

# """# Optimization"""
# from tensorflow.keras.optimizers import RMSprop

# opt = RMSprop(lr=0.0001, decay=1e-6)
# opt = Adam(1e-4)
# # opt = Adam(lr=0.001)
# model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])
# opt =(learning_rate=0.1)
opt = Adam(learning_rate=0.001, decay=1e-6)
model.compile(loss='mse',optimizer=opt, metrics=['accuracy'])
# model.compile(
#     loss='sparse_categorical_crossentropy',
#     optimizer=opt,
#     metrics=['accuracy']
# )


# importing pretrained and optimized model 
# model = load_model('vgg16Model.h5')

# OpenCV and VGG16 object detection 
class ObjectDetection():
    
    def __init__(self):
        self.objects = []

    # function to break videos into frames
    def to_frames(self, video_upload):
        if not os.path.exists('static'): 
            os.makedirs('static')
            if not os.path.exists('uploads'): 
                os.makedirs('uploads')
            if not os.path.exists('frames'): 
                os.makedirs('frames')     
        with open(os.path.join("static/uploads", video_upload.name),"wb") as f:
         f.write(video_upload.getbuffer())
         video_file_path = "./static/uploads/"+str(video_upload.name)
         st.write("saved uploaded file")
        cap = cv2.VideoCapture(video_file_path)
        st.write('[RUNNING>>] Framing Video File....' + video_upload.name)
        count = 0
        while(True):
          ret, frame = cap.read()
          if not ret: 
            break
          if cv2.waitKey(1) & 0xFF == ord('q'):
            break
          name = 'static/frames/' + (video_upload.name).split('.')[0] + str(count) + '.jpg'
          cv2.imwrite(name, frame)
          count += 1

    # detecting objects from frames
    def detect_object(self):
        st.write('[RUNNING>>] Detection Process....')
        for item in self.get_frames():  
            original_image = load_img(item, target_size=(224, 224))
            image = img_to_array(original_image)
            image = np.expand_dims(image, axis=0)
            image = preprocess_input(image)
            y_pred = model.predict(image)
            label = decode_predictions(y_pred)
            self.objects.append(label[0][1][1])
        st.write('[STATUS>>] Finalizing Predictions ...')                                                                                                                                                                                                                                                                   
        with open('detected_objects.txt', 'w') as f:
            f.write(json.dumps(self.objects))
                
    # capturing detected objects
    def get_objects(self):
        return self.objects
    
    # setting frames into an array to be searchable
    def get_frames(self):
        FRAMES_ARR =  glob.glob("static/frames/*.jpg")
        return FRAMES_ARR
    
    # function to search for detected objects
    def search_for(self, _object):
        st.write('[RUNNING>>] Searching ...')
        with open('detected_objects.txt', 'r') as f:
            objects = list(json.loads(f.read()))
        results = []
        if _object in set(objects):
            for i in range(len(objects)):
                if _object.__eq__(objects[i]):
                    frame_path = self.get_frames()[i]
                    results.append(frame_path) 
        else:
            return "There is no such file"
        return results

# creating an instance of the Object Detection class
detector=ObjectDetection()

html_render_title = """
    <style="color:black;text-align:center;>KBS Assignment 2</style>
    """ 
html_temp = """
    <div style ="background-color:yellow;padding:13px">
    <h1 style ="color:black;text-align:left;">Keras & OpenCV Project</h1>
    </div>
    """
html_side_temp = """
    <div style ="padding:13px">
    <h1 style ="color:black;text-align:center;">Project Engineers</h1>
    <h3 style ="color:black;text-align:center;">Magaya Makomborero r181571b</h3>
    <h3 style ="color:black;text-align:center;">Mabhuka Oswell r181573f</h3>
    </div>
    """    
st.title("KBS Assignment 2")
st.markdown(html_temp, unsafe_allow_html = True)
st.sidebar.markdown(html_side_temp, unsafe_allow_html = True)
x = st.slider('Change Threshold value',min_value = 50,max_value = 255)
videoLocation = st.file_uploader("Upload a Video:", type=["mp4", "mpeg", "avchd", "wmv", "mov", "avi", "flv", "webm"])

btn = st.button("Detect and Predict")

if btn:
    detector.to_frames(videoLocation)
    detector.detect_object()
    frames = detector.get_objects()
    st.title('Frames for:', videoLocation.name)
    st.write(detector.get_objects())
    
searchimage = st.text_input("Enter Object Name: ")
searchbtn = st.button("Search Object")
if searchbtn:
    searched = detector.search_for(searchimage)
    st.title("Search Results")
    for img in searched:
        with st.beta_container():
            for col in st.beta_columns(1):
                col.image(img, width=150, caption=searchimage, use_column_width=True) 






